{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f263ae",
   "metadata": {},
   "source": [
    "Table Transformer Training Notebook (with Split + Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c82dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kawi two\\.conda\\envs\\tables-detr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('table-transformer/detr')\n",
    "import sys\n",
    "sys.path.append('table-transformer/detr')\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "from models import build_model\n",
    "from datasets.coco import build as build_coco_dataset\n",
    "import util.misc as utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7b924",
   "metadata": {},
   "source": [
    "STEP 1: Prepare Dataset from Mixed Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2bf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Prepare Dataset from Mixed Inputs ---\n",
    "import xml.etree.ElementTree as ET\n",
    "images_dir = Path(\"PubTables-1M-Detection_Images_Test\")\n",
    "annotations_dir = Path(\"PubTables-1M-Detection_Annotations_Test\")\n",
    "coco_out = Path(\"coco_split\")\n",
    "(coco_out / \"train2017\").mkdir(parents=True, exist_ok=True)\n",
    "(coco_out / \"val2017\").mkdir(exist_ok=True)\n",
    "(coco_out / \"annotations\").mkdir(exist_ok=True)\n",
    "\n",
    "def parse_voc_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    file_name = root.find('filename').text\n",
    "    size = root.find('size')\n",
    "    width = int(float(size.find('width').text))\n",
    "    height = int(float(size.find('height').text))\n",
    "    anns = []\n",
    "    for obj in root.findall('object'):\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        anns.append({\n",
    "            'bbox': [xmin, ymin, xmax - xmin, ymax - ymin],\n",
    "            'category_id': 1\n",
    "        })\n",
    "    return file_name, width, height, anns\n",
    "\n",
    "def split_list(lst, frac=0.8):\n",
    "    random.shuffle(lst)\n",
    "    k = int(frac * len(lst))\n",
    "    return lst[:k], lst[k:]\n",
    "\n",
    "xml_files = list(annotations_dir.glob(\"*.xml\"))\n",
    "train_xmls, val_xmls = split_list(xml_files)\n",
    "\n",
    "def build_coco_from_xmls(xml_list, split_name, start_img=0, start_ann=0):\n",
    "    coco = {\"images\": [], \"annotations\": [], \"categories\": [{\"id\": 1, \"name\": \"table\"}]}\n",
    "    img_id, ann_id = start_img, start_ann\n",
    "    for xml_file in xml_list:\n",
    "        file_name, w, h, anns = parse_voc_xml(xml_file)\n",
    "        img_path = images_dir / file_name\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "        coco[\"images\"].append({\"id\": img_id, \"file_name\": file_name, \"width\": w, \"height\": h})\n",
    "        for a in anns:\n",
    "            x, y, bw, bh = a[\"bbox\"]\n",
    "            coco[\"annotations\"].append({\"id\": ann_id, \"image_id\": img_id, \"category_id\": 1, \"bbox\": [x, y, bw, bh], \"area\": bw*bh, \"iscrowd\": 0})\n",
    "            ann_id += 1\n",
    "        shutil.copy2(img_path, coco_out / split_name / file_name)\n",
    "        img_id += 1\n",
    "    return coco, img_id, ann_id\n",
    "\n",
    "train_coco, next_img, next_ann = build_coco_from_xmls(train_xmls, \"train2017\")\n",
    "val_coco, _, _ = build_coco_from_xmls(val_xmls, \"val2017\", start_img=next_img, start_ann=next_ann)\n",
    "\n",
    "with open(coco_out / \"annotations\" / \"instances_train2017.json\", \"w\") as f:\n",
    "    json.dump(train_coco, f)\n",
    "with open(coco_out / \"annotations\" / \"instances_val2017.json\", \"w\") as f:\n",
    "    json.dump(val_coco, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed24917d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'table_transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtable_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtable_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_coco_dataset\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtable_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_one_epoch, evaluate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'table_transformer'"
     ]
    }
   ],
   "source": [
    "# --- STEP 2: Training Starts Here ---\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from table_transformer.src.models import build_model\n",
    "from table_transformer.src.datasets import build_coco_dataset\n",
    "from table_transformer.src.engine import train_one_epoch, evaluate\n",
    "import table_transformer.src.util.misc as utils\n",
    "\n",
    "# --- 📁 Config path ---\n",
    "config_path = \"table-transformer/src/detection_config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "config = argparse.Namespace(**config_dict)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = str(coco_out)\n",
    "\n",
    "args_for_dataset = argparse.Namespace(**{**config_dict, 'coco_path': data_path, 'masks': False})\n",
    "\n",
    "# --- 🧠 Build model ---\n",
    "model, criterion, postprocessors = build_model(config)\n",
    "model.to(device)\n",
    "\n",
    "# --- 📊 Dataset loaders ---\n",
    "dataset_train = build_coco_dataset(image_set='train', args=args_for_dataset)\n",
    "dataset_val = build_coco_dataset(image_set='val', args=args_for_dataset)\n",
    "\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "batch_size = getattr(config, 'batch_size', 2)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=batch_size, sampler=sampler_train, drop_last=True, num_workers=2, collate_fn=utils.collate_fn)\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=batch_size, sampler=sampler_val, drop_last=False, num_workers=2, collate_fn=utils.collate_fn)\n",
    "\n",
    "# --- 🔧 Optimizer & Scheduler ---\n",
    "param_dicts = [\n",
    "    {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "    {\"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad], \"lr\": getattr(config, 'lr_backbone', 1e-5)}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(param_dicts, lr=getattr(config, 'lr', 1e-4), weight_decay=getattr(config, 'weight_decay', 1e-4))\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=getattr(config, 'lr_drop', 40), gamma=0.1)\n",
    "\n",
    "output_dir = os.path.join(data_path, \"output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "num_epochs = getattr(config, 'epochs', 2)\n",
    "\n",
    "# --- 📈 Training Loop with Dynamic Config Reload ---\n",
    "for epoch in range(num_epochs):\n",
    "    # 🔄 Reload config each epoch\n",
    "    with open(config_path, 'r') as f:\n",
    "        updated_config_dict = json.load(f)\n",
    "    config = argparse.Namespace(**updated_config_dict)\n",
    "\n",
    "    # 💡 Allow early stopping or extending\n",
    "    updated_epochs = getattr(config, 'epochs', num_epochs)\n",
    "    if epoch >= updated_epochs:\n",
    "        print(f\"🛑 Stopping early at epoch {epoch} (new config epochs: {updated_epochs})\")\n",
    "        break\n",
    "\n",
    "    # 🔄 Update optimizer learning rates dynamically\n",
    "    optimizer.param_groups[0]['lr'] = getattr(config, 'lr', 1e-4)\n",
    "    optimizer.param_groups[1]['lr'] = getattr(config, 'lr_backbone', 1e-5)\n",
    "    lr_scheduler.step_size = getattr(config, 'lr_drop', 40)\n",
    "\n",
    "    print(f\"\\n📘 Epoch {epoch+1}/{updated_epochs} — LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    # --- 🔁 Training ---\n",
    "    train_stats = train_one_epoch(model, criterion, data_loader_train, optimizer, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # --- ✅ Validation ---\n",
    "    base_ds_val = dataset_val.coco\n",
    "    val_stats, coco_evaluator = evaluate(\n",
    "        model, criterion, postprocessors, data_loader_val, base_ds_val, device, output_dir\n",
    "    )\n",
    "\n",
    "    val_loss = val_stats.get('loss', float('inf'))\n",
    "    print(f\"📊 Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    if coco_evaluator and coco_evaluator.coco_eval:\n",
    "        stats = coco_evaluator.coco_eval['bbox'].stats\n",
    "        print(f\"🧪 mAP@0.5: {stats[1]:.3f}, AP@[0.5:0.95]: {stats[0]:.3f}\")\n",
    "\n",
    "    if 'class_error' in val_stats:\n",
    "        print(f\"🎯 Validation Accuracy: {100 - val_stats['class_error']:.2f}%\")\n",
    "\n",
    "    # --- 💾 Save checkpoint ---\n",
    "    checkpoint = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch + 1,\n",
    "        'config': updated_config_dict\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(output_dir, f\"checkpoint_epoch_{epoch+1}.pth\"))\n",
    "    torch.save(model.state_dict(), os.path.join(output_dir, \"model_final.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2059a",
   "metadata": {},
   "source": [
    "COCO Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66852940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/predictions.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     coco_eval\u001b[38;5;241m.\u001b[39msummarize()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/predictions.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco_split/annotations/instances_val2017.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[1;34m(pred_json_path, gt_json_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mEvaluate predictions in COCO format against ground truth annotations.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m coco_gt \u001b[38;5;241m=\u001b[39m COCO(gt_json_path)\n\u001b[1;32m----> 9\u001b[0m coco_dt \u001b[38;5;241m=\u001b[39m \u001b[43mcoco_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadRes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_json_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m coco_eval \u001b[38;5;241m=\u001b[39m COCOeval(coco_gt, coco_dt, iouType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m coco_eval\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\kawi two\\.conda\\envs\\tables-detr\\lib\\site-packages\\pycocotools\\coco.py:319\u001b[0m, in \u001b[0;36mCOCO.loadRes\u001b[1;34m(self, resFile)\u001b[0m\n\u001b[0;32m    317\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(resFile) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (PYTHON_VERSION \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(resFile) \u001b[38;5;241m==\u001b[39m unicode):\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresFile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    320\u001b[0m         anns \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(resFile) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/predictions.json'"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "def evaluate_predictions(pred_json_path, gt_json_path):\n",
    "    \"\"\"\n",
    "    Evaluate predictions in COCO format against ground truth annotations.\n",
    "    \"\"\"\n",
    "    coco_gt = COCO(gt_json_path)\n",
    "    coco_dt = coco_gt.loadRes(pred_json_path)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "# Example usage:\n",
    "evaluate_predictions(\n",
    "    \"output/predictions.json\",\n",
    "    \"coco_split/annotations/instances_val2017.json\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
